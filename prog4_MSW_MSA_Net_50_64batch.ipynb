{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import AdamW\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#import cv2 \n",
    "from PIL import Image \n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "#import tensorflow.compat.v1 as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/Melspectro_featmaps'\n",
    "img_size=224\n",
    "batch_size=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data augmentor \n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, \n",
    "\t\t\t\t\t\t\t\tzoom_range=0.2, horizontal_flip=True, \n",
    "\t\t\t\t\t\t\t\tvalidation_split=0.2) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, \n",
    "\t\t\t\t\t\t\t\tvalidation_split=0.2) \n",
    "\n",
    "# Create datasets \n",
    "train_datagen = train_datagen.flow_from_directory(base_dir, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size=( \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\timg_size, img_size), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsubset='training', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t) \n",
    "test_datagen = test_datagen.flow_from_directory(base_dir, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size=( \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\timg_size, img_size), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsubset='validation', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "train_datagen.reset()\n",
    "x_train, y_train= next(train_datagen)\n",
    "for i in tqdm.tqdm(range(int(train_datagen.n/batch_size)-1)): \n",
    "  img, label = next(train_datagen)\n",
    "  x_train = np.append(x_train, img, axis=0 )\n",
    "  y_train = np.append(y_train, label, axis=0)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "test_datagen.reset()\n",
    "x_test, y_test = next(test_datagen)\n",
    "for i in tqdm.tqdm(range(int(test_datagen.n/batch_size)-1)): \n",
    "  img, label = next(test_datagen)\n",
    "  x_test = np.append(x_test, img, axis=0 )\n",
    "  y_test = np.append(y_test, label, axis=0)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_split = 0.05\n",
    "weight_decay = 1e-2\n",
    "label_smoothing = 0.05\n",
    "\n",
    "steps_per_epoch = 15000 // 64  # = 234\n",
    "decay_steps = 234 * 100         # = 23400\n",
    "\n",
    "#lr_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    #initial_learning_rate=1e-4,\n",
    "    #decay_steps=decay_steps,\n",
    "    #alpha=1e-5)  # Final LR fraction of initial LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = int(len(x_train) * (1 - validation_split))\n",
    "num_val_samples = len(x_train) - num_train_samples\n",
    "x_train, x_val = np.split(x_train, [num_train_samples])\n",
    "y_train, y_val = np.split(y_train, [num_train_samples])\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(x_val.shape, y_val.shape)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(    monitor='val_loss',        # What metric to monitor\n",
    "    patience=5,                # Stop if no improvement after 5 epochs\n",
    "    restore_best_weights=True # Roll back to best weights after stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    B, H, W, C = tf.shape(x)[0], x.shape[1], x.shape[2], x.shape[3]\n",
    "    x = tf.reshape(x, shape=(B, H // window_size, window_size, W // window_size, window_size, C))\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape=(-1, window_size, window_size, C))\n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(windows, shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels))\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.drop_prob == 0. or not self.trainable:\n",
    "            return x\n",
    "        input_shape = tf.shape(x)\n",
    "        batch_size = input_shape[0]\n",
    "        rank = x.shape.rank\n",
    "        shape = (batch_size,) + (1,) * (rank - 1)\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        return tf.math.divide(x, 1 - self.drop_prob) * path_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(num_window_elements, self.num_heads),\n",
    "            initializer=tf.initializers.Zeros(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.Variable(\n",
    "            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
    "        )\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(self.relative_position_index, shape=(-1,))\n",
    "        relative_position_bias = tf.gather(self.relative_position_bias_table, relative_position_index_flat)\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
    "        )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
    "            attn = tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size)) + mask_float\n",
    "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "\n",
    "        attn = self.dropout(attn)\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0,\n",
    "                 num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.num_patch = num_patch\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.num_mlp = num_mlp\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, dropout_rate=dropout_rate\n",
    "        )\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(num_mlp),\n",
    "            layers.Activation(keras.activations.gelu),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(dim),\n",
    "            layers.Dropout(dropout_rate),\n",
    "        ])\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(mask_windows, (-1, self.window_size * self.window_size))\n",
    "            attn_mask = np.expand_dims(mask_windows, axis=1) - np.expand_dims(mask_windows, axis=2)\n",
    "            attn_mask = np.where(attn_mask != 0, -100.0, 0.0)\n",
    "            self.attn_mask = tf.constant(attn_mask, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(x_windows, shape=(-1, self.window_size * self.window_size, channels))\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "        attn_windows = tf.reshape(attn_windows, shape=(-1, self.window_size, self.window_size, channels))\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, channels)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtract(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size_x = patch_size[0]\n",
    "        self.patch_size_y = patch_size[1]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            rates=(1, 1, 1, 1),\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patch_num = patches.shape[1]\n",
    "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patches, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim=num_patches, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dimension=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim):\n",
    "        super().__init__()\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
    "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mswmsa_t(input_shape=(224, 224, 3), num_classes=5,\n",
    "                 patch_size=4, embed_dim=96,\n",
    "                 depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, dropout_rate=0.1):\n",
    "\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    x = PatchExtract(patch_size=(patch_size, patch_size))(input)\n",
    "\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
    "    patch_resolution = (input_shape[0] // patch_size, input_shape[1] // patch_size)\n",
    "\n",
    "    x = PatchEmbedding(num_patches=num_patches, embed_dim=embed_dim)(x)\n",
    "\n",
    "    # Stage 1 (depth=2)\n",
    "    for i in range(2):\n",
    "        shift_size = 0 if i % 2 == 0 else window_size // 2\n",
    "        print(f\"Stage 1 - {'W-MSA' if shift_size == 0 else 'SW-MSA'}_{i + 1}\")\n",
    "        x = SwinTransformer(\n",
    "            dim=embed_dim, num_patch=patch_resolution, num_heads=num_heads[0],\n",
    "            window_size=window_size, shift_size=shift_size,\n",
    "            num_mlp=int(embed_dim * mlp_ratio), qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate\n",
    "        )(x)\n",
    "\n",
    "    # Patch Merging 1\n",
    "    x = PatchMerging(patch_resolution, embed_dim)(x)\n",
    "    patch_resolution = (patch_resolution[0] // 2, patch_resolution[1] // 2)\n",
    "    embed_dim *= 2\n",
    "\n",
    "    # Stage 2 (depth=2)\n",
    "    for i in range(2):\n",
    "        shift_size = 0 if i % 2 == 0 else window_size // 2\n",
    "        print(f\"Stage 2 - {'W-MSA' if shift_size == 0 else 'SW-MSA'}_{i + 1}\")\n",
    "        x = SwinTransformer(\n",
    "            dim=embed_dim, num_patch=patch_resolution, num_heads=num_heads[1],\n",
    "            window_size=window_size, shift_size=shift_size,\n",
    "            num_mlp=int(embed_dim * mlp_ratio), qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate\n",
    "        )(x)\n",
    "\n",
    "    # Patch Merging 2\n",
    "    x = PatchMerging(patch_resolution, embed_dim)(x)\n",
    "    patch_resolution = (patch_resolution[0] // 2, patch_resolution[1] // 2)\n",
    "    embed_dim *= 2\n",
    "\n",
    "    # Stage 3 (depth=6)\n",
    "    for i in range(6):\n",
    "        shift_size = 0 if i % 3 == 0 else window_size // 2\n",
    "        print(f\"Stage 3 - {'W-MSA' if shift_size == 0 else 'SW-MSA'}_{i + 1}\")\n",
    "        x = SwinTransformer(\n",
    "            dim=embed_dim, num_patch=patch_resolution, num_heads=num_heads[2],\n",
    "            window_size=window_size, shift_size=shift_size,\n",
    "            num_mlp=int(embed_dim * mlp_ratio), qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate\n",
    "        )(x)\n",
    "\n",
    "    # Patch Merging 3\n",
    "    x = PatchMerging(patch_resolution, embed_dim)(x)\n",
    "    patch_resolution = (patch_resolution[0] // 2, patch_resolution[1] // 2)\n",
    "    embed_dim *= 2\n",
    "\n",
    "    # Stage 4 (depth=2)\n",
    "    for i in range(2):\n",
    "        shift_size = 0 if i % 2 == 0 else window_size // 2\n",
    "        print(f\"Stage 4 - {'W-MSA' if shift_size == 0 else 'SW-MSA'}_{i + 1}\")\n",
    "        x = SwinTransformer(\n",
    "            dim=embed_dim, num_patch=patch_resolution, num_heads=num_heads[3],\n",
    "            window_size=window_size, shift_size=shift_size,\n",
    "            num_mlp=int(embed_dim * mlp_ratio), qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate\n",
    "        )(x)\n",
    "\n",
    "\n",
    "    # Classification Head\n",
    "    x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mswmsa_t()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "class ResumeTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_dir=\"checkpoints\"):\n",
    "        super().__init__()\n",
    "        self.save_dir = save_dir\n",
    "        self.total_train_time = 0\n",
    "        self.total_val_time = 0\n",
    "        self.epoch_times = []  # Store per-epoch timing\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_train_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_train_time = time.time() - self.epoch_train_start\n",
    "        self.total_train_time += epoch_train_time\n",
    "\n",
    "        # Save this epoch's times\n",
    "        epoch_time_info = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_time_sec\": round(epoch_train_time, 2),\n",
    "            \"val_time_sec\": round(self.last_val_time, 2) if hasattr(self, 'last_val_time') else 0.0\n",
    "        }\n",
    "        self.epoch_times.append(epoch_time_info)\n",
    "\n",
    "        # Print per-epoch times\n",
    "        print(f\"\\n Epoch {epoch+1} - Train Time: {epoch_time_info['train_time_sec']}s | Val Time: {epoch_time_info['val_time_sec']}s\")\n",
    "\n",
    "        # Save epoch timing info to file\n",
    "        with open(os.path.join(self.save_dir, \"epoch_times.json\"), \"w\") as f:\n",
    "            json.dump(self.epoch_times, f, indent=2)\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        self.val_start_time = time.time()\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        self.last_val_time = time.time() - self.val_start_time\n",
    "        self.total_val_time += self.last_val_time\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f\"\\n Total Training Time: {self.total_train_time:.2f} sec\")\n",
    "        print(f\" Total Validation Time: {self.total_val_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"mswmsa\"\n",
    "checkpoint_dir = f\"checkpoints_{experiment_name}\"\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save/load epoch functions\n",
    "def save_epoch(epoch):\n",
    "    with open(os.path.join(checkpoint_dir, \"epoch.json\"), \"w\") as f:\n",
    "        json.dump({\"epoch\": epoch}, f)\n",
    "\n",
    "def load_epoch():\n",
    "    try:\n",
    "        with open(os.path.join(checkpoint_dir, \"epoch.json\")) as f:\n",
    "            return json.load(f)[\"epoch\"]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = load_epoch()\n",
    "if latest_epoch > 0:\n",
    "    model.load_weights(os.path.join(checkpoint_dir, \"model.weights.h5\"))\n",
    "    print(f\"Resumed from epoch {latest_epoch}\")\n",
    "else:\n",
    "    print(\"Starting from scratch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, \"model.weights.h5\"),\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_time_cb = ResumeTimeCallback(save_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x):\n",
    "    x = tf.image.random_crop(x, size=(image_dimension, image_dimension, 3))\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "\n",
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(lambda x, y: (augment(x), y))\n",
    "    .batch(batch_size=batch_size)\n",
    "    #.map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset_val = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    .batch(batch_size=batch_size)\n",
    "    #.map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset_test = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(batch_size=batch_size)\n",
    "    #.map(lambda x, y: (patch_extract(x), y))\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "    optimizer=tf.keras.optimizers.experimental.AdamW(\n",
    "        learning_rate=1e-4, weight_decay=1e-2\n",
    "    ),\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training steps per epoch:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_mswmsa_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    validation_data=dataset_val, \n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch = len(dataset),\n",
    "    validation_steps = len(dataset_val),\n",
    "    initial_epoch=latest_epoch,\n",
    "    callbacks=[\n",
    "        checkpoint_cb,\n",
    "        LambdaCallback(on_epoch_end=lambda epoch, logs: save_epoch(epoch + 1)),\n",
    "        resume_time_cb,\n",
    "        early_stopping\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, top_5_accuracy = model.evaluate(dataset_test)\n",
    "print(f\"Test loss: {round(loss, 2)}\")\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "labels=[]\n",
    "for im, label in dataset_test :\n",
    "    predicted.append(model(im))\n",
    "    labels.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= np.concatenate([np.argmax(predicted[:-1],axis=-1).flatten(),np.argmax(predicted[-1],axis=-1).flatten()])\n",
    "lab= np.concatenate([np.argmax(labels[:-1],axis=-1).flatten(),np.argmax(labels[-1],axis=-1).flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=['classA','classB','classC','classD','classE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for   images,labels in  dataset_test.take(10):\n",
    "  for i   in range(16):\n",
    "   ax=plt.subplot(4,4,i+1)\n",
    "\n",
    "   plt.imshow(images[i])\n",
    "   plt.title(\"True Label :\"+ class_name[tf.argmax(labels[i],axis=0).numpy()] + \"\\n\" + \"Predicted Label  : \" + class_name[tf.argmax(model(tf.expand_dims(images[i],axis=0)),axis= -1).numpy()[0]])\n",
    "   plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix,confusion_matrix\n",
    "cm=confusion_matrix(lab,pred)\n",
    "print(cm)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel(\"Predicted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
